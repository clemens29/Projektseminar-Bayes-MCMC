% Latex document @author Clemens Näther, Jakub Kliemann, s85426, s85515
%--------------------------------------------------------------------
\documentclass[a4paper,12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage[hidelinks]{hyperref}
\usepackage{float}
\usepackage{listings}
\usepackage{color}
\usepackage{amsmath}
\usepackage{pdfpages}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{geometry}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{mhchem}

\usepackage{biblatex} % Verwende BibLaTeX
\addbibresource{bibliography.bib} % Deine .bib-Datei

\lstset{ %
  language=,
  basicstyle=\ttfamily\small,
  backgroundcolor=\color{lightgray!20},
  frame=single,
  columns=fullflexible,
  breaklines=true,
  captionpos=b
}

\geometry{a4paper, top=25mm, left=30mm, right=25mm, bottom=30mm,
headsep=10mm, footskip=12mm}

\pagestyle{fancy}

\lhead{Dokumentation}

\rhead{Seite \thepage\ von \pageref{LastPage}}

\cfoot{}

\renewcommand{\headrulewidth}{0.4pt}

\renewcommand{\footrulewidth}{0.4pt}

\begin{document}

\begin{titlepage}

\begin{center}

\includegraphics[height=4cm]{../images/htwd-logo.jpg}\\[1cm]

\textsc{\LARGE Hochschule für Technik und Wirtschaft}\\[1.5cm]

\textsc{\Large Dokumentation}\\[0.5cm]

% Title
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\HRule \\[0.4cm]
{ \huge \bfseries \textsc{Projektseminar}}\\[0.4cm]
{ \huge \bfseries \textsc{Optimierung und Unsicherheitsquantifizierung mit Bayesianischer Statistik und MCMC-Methoden}}\\[0.4cm]
{ \huge \bfseries \textsc{(Prof. Schwarzenberger)}}\\[0.4cm]
\HRule \\[1.5cm]

% Author and supervisor
\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large

\emph{Clemens Näther, s85426}\\
\emph{Jakub Kliemann, s85515}\\

\end{flushleft}
\end{minipage}
\end{center}
\end{titlepage}

\tableofcontents
\newpage

\section{Einleitung}
\newpage

\section{Theoretischer Teil}

\subsection{Grundlagen der bayesianischen Statistik und das Bayes'sche Theorem}
\subsubsection{Einführung in die bayesianische Statistik}

Die bayesianische Statistik ist ein Zweig der Statistik. Sie unterscheidet sich im wesentlichen in der Interpretation der Wahrscheinlichkeit von der klassischen Statistik. Die klassische Statistik definiert die Wahrscheinlichkeit als die \textbf{relative Häufigkeit} in einem Zufallsexperiment \parencite[2]{StatistikKlassischOderBayes}. In der bayesianischen Statistik hingegen wird die Wahrscheinlichkeit als Grad des Glaubens respektiv als \textbf{Plausibilität} eines Ereignisses oder einer Aussage interpretiert \parencite[1]{EinfBayesStatistik}. \\\\
Kern der bayesianischen Statistik ist es Wissen über ein Ereignis zu verfeinern, sobald neue Informationen vorliegen. Dazu nutzt man hauptsächlich das \textbf{Bayes'sche Theorem}, welches erlaubt das Vorwissen (Prior) mit neuen Daten (Likelihood) zu kombinieren und daraus eine aktualisierte Wahrscheinlichkeit (Posterior) zu berechnen. \\\\
Mit Hilfe des Bayes'schen Theorems kann man unbekannte Parameter schätzen, ein Konfidenzintervall für diese Parameter angeben und Hypothesen prüfen. Die klassische Statistik benötigt hingegen dafür Testgrößen, weshalb die bayesianische Statistik als flexibler und intuitiver gilt. \parencite[1]{EinfBayesStatistik}. \\\\
Problem der bayesianischen Statistik ist jedoch, dass die Berechnung der Posterioriverteilung analytisch oft nicht möglich ist. Da es nun aber gute numerische Methoden wie die \textbf{Markov Chain Monte Carlo (MCMC)} Methoden gibt, findet die bayesianische Statistik immer mehr Anwendungen. So zum Beispiel in der Medizin oder für künstliche Intelligenzen. \parencite[1]{StatistikKlassischOderBayes}.

\subsubsection{Das Bayes'sche Theorem und seine Bestandteile}

Das Bayes'sche Theorem ist ein fundamentales Konzept der bayesianischen Statistik.Es beschreibt, wie man vorhandenes Vorwissen durch neue Daten aktualisiert. \\\\
Die \textbf{Prioriverteilung} beschreibt die anfänglichen Annahmen oder das Vorwissen über einen 
Parameter oder ein Ereignis, bevor neue Daten berücksichtigt werden.
Dabei ``enthält die Priorverteilung eines Parameters $\theta$, ausgedrückt durch f ($ \theta $), 
was man vor Auswertung der Stichprobe über $\theta$ weiß.'' \parencite[90]{StatistikKlassischOderBayes}. \\
Als Priori-Wahrscheinlichkeit wird somit die Wahrscheinlichkeit $ P(A) $ bezeichnet. \\\\
Die \textbf{Posterioriverteilung} beschreibt das Wissen über einen Parameter oder ein Ereignis, nachdem alle 
vorhandenen Daten berücksichtigt wurden. Durch die neuen Daten, meist einer Stichprobe, wird die 
anfängliche Annahme, die durch die Prioriverteilung ausgedrückt wird, aktualisiert. 
Dies führt zu einer neuen Verteilung die widerspiegelt, wie wahrscheinlich verschiedene Werte 
des Parameters auf Grundlage sowohl des Vorwissens als auch der neuen Informationen sind. \parencite[109]{StatistikKlassischOderBayes}\\
Die Posteriori-Wahrscheinlichkeit wird somit als $ P(A|B) $ bezeichnet. \\\\
Die \textbf{Likelihood-Funktion} enthält die Informationen, die die Daten über den Parameter oder das Ereignis liefern.
Dabei beschreibt die Likelihood die Informationen aus den neuen Daten, die zur Aktualisierung der Prioriverteilung beitragen. \parencite[88]{StatistikKlassischOderBayes}\\
Die Likelihood-Wahrscheinlichkeit wird somit als $ P(B|A) $ bezeichnet. \\\\
Die Wahrscheinlichkeit $ P(B) $ wird als Normierungskonstante bezeichnet. Sie sorgt dafür, 
dass die Posterioriverteilung korrekt normiert ist, das heißt, dass die Summe der 
Wahrscheinlichkeiten aller möglichen Werte des Parameters 1 ergibt. \parencite[109]{StatistikKlassischOderBayes} \\\\
Das Bayes'sche Theorem lässt sich somit wie folgt darstellen:
\begin{equation}
P(A|B) = \frac{P(A) \cdot P(B|A)}{P(B)}
\end{equation}
Das Bayes'sche Theorem lässt sich auch rekursiv anwenden \parencite[17]{EinfBayesStatistik}. \\
Gegeben sei das Ereignis $A$ sowie die Teilergebnisse $B_1, B_2, ..., B_n$. Dann ergibt sich die Wahrscheinlichkeit $P(A|B_1)$ zu:
\begin{equation}
P(A|B_1) = \frac{P(A) \cdot P(B_1|A)}{P(B_1)}
\end{equation}
Nun wird die Information $B_2$ hinzugefügt. Die Wahrscheinlichkeit $P(A|B_1, B_2)$ ergibt sich bei Unabhängigkeit von den Teilereignissen $B_1, B_2, ..., B_n$ zu:
\begin{equation}
P(A|B_1, B_2) = \frac{P(A) \cdot P(B_1|A) \cdot P(B_2|A)}{P(B_1) \cdot P(B_2)}
\end{equation}
Weiterhin lässt sich diese Formel umstellen, wodurch deutlich wird, dass beim Hinzufügen von neuen Informationen die Posterioriverteilung aktualisiert wird:
\begin{equation}
P(A|B_1, B_2) = \frac{P(A) \cdot P(B_1|A) \cdot P(B_2|A)}{P(B_1) \cdot P(B_2)} = P(A|B_1) \cdot \frac{P(B_2|A)}{P(B_2)}
\end{equation}
Dies lässt sich allgemein formulieren für:
\begin{equation}
P(A|B_1, B_2, ..., B_n) = P(A|B_1, B_2, ..., B_{n-1}) \cdot \frac{P(B_n|A)}{P(B_n)}
\end{equation}
Die Wahl der Prioriverteilung ist ein wichtiger Aspekt der bayesianischen Statistik. Sie wird immer so gewählt, dass die Entropie maximal ist. Die Entropie ist ein Maß für die Unsicherheit, was bedeutet, dass nur Informationen enthalten sind, die vor der Beobachtung bekannt sind. \parencite[57]{EinfBayesStatistik}. Unter folgenden Bedingungen ist die Prioriverteilung optimal \parencite[59]{EinfBayesStatistik}:
\begin{itemize}
  \item Zufallsvariablen, die in $[a,b]$ definiert sind, sind \textbf{gleichverteilt}
  \item Zufallsvariablen mit gegebenen Mittelwert und Varianz sind \textbf{normalverteilt}
  \item Zufallsvariablen mit gegebenen Mittelwert sind \textbf{exponentialverteilt}
  \item Zufallsvariablen mit gegebenen Mittelwert und Varianz im Intervall [0,$\infty$] besitzen eine \textbf{abgeschnittene Normalverteilung}
\end{itemize}
Wenn keine Informationen über den Parameter vorliegen, wird eine \textbf{uninformative} Prioriverteilung gewählt. Es handelt sich dabei um eine uneigentliche Verteilung. \parencite[57]{EinfBayesStatistik}.

\subsubsection{Beispiele und praktische Anwendungen}
\textbf{Beispiel 1}: $m$ gleichgeformte Kugeln, unter denen sich $k$ rote Kugeln und $m-k$ schwarze Kugeln befinden. Eine Kugel wird zufällig gezogen. 
Die Wahrscheinlichkeit, dass die gezogene Kugel rot ist, beträgt 
\begin{equation}
P(A) = \frac{k}{m} = p
\end{equation}
Der Versuch wird erweitert, sodass $n$-mal eine Kugel mit Zurücklegen gezogen wird.
Die Wahrscheinlichkeit, dass $x$-mal eine rote Kugel bie $n$-maligem Ziehen gezogen wird,
beträgt
\begin{equation}
P(x|n,p) = \binom{n}{x} \cdot p^x \cdot (1-p)^{n-x}
\end{equation}
Sei nun $p$ unbekannt. Dieses $p$ ist nun zu schätzen.
Die Binomialverteilung wird nun als Likelihood-Funktion verwendet:
\begin{equation}
P(n,x|p) = \binom{n}{x} \cdot p^x \cdot (1-p)^{n-x}
\end{equation}
wobei $0 \leq p \geq 1$.
Als Prioridichte wird die Gleichverteilung verwendet, da es keine Informationen über $p$ gibt.
\begin{equation}
  P(p) =
  \begin{cases}
    1, & \text{für } 0 \leq p \leq 1 \\
    0, & \text{sonst}
  \end{cases}
\end{equation}
Die Posterioridichte ergibt sich somit zu:
\begin{equation}
P(p|n,x) = \frac{\binom{n}{x}  p^x \cdot (1-p)^{n-x}}{P(n,x)}
\label{eq:posterior}
\end{equation}
Vergleicht man dies mit der Dichtefunktion der Beta-Verteilung, so erkennt man dass die Posterioridichte einer Beta-Verteilung entspricht.
\begin{equation}
P(p|n,x) = \frac{(n+1)!}{x!\cdot(n-x)!} \cdot p^x \cdot (1-p)^{n-x}
= \frac{\Gamma(n+1)}{\Gamma(x+1)\cdot\Gamma(n-x+1)} \cdot p^x \cdot (1-p)^{n-x}
\end{equation}
Somit suche nach Maximum der Posterioridichte, um den Schätzer für $p$ zu finden.
\begin{equation}
\frac{d}{dp} P(p|n,x) = xp^{x-1} \cdot (1-p)^{n-x} - (n-x)p^x \cdot (1-p)^{n-x-1} = 0
\end{equation}
\begin{equation}
\Rightarrow xp^{x-1} \cdot (1-p)^{n-x} = (n-x)p^x \cdot (1-p)^{n-x-1}
\end{equation}
Vereinfacht ergibt sich:
\begin{equation}
\Rightarrow x(1-p) = (n-x)p
\end{equation}
\begin{equation}  
\Rightarrow \frac{x}{p} - \frac{n-x}{1-p} = 0
\end{equation}
\begin{equation}
\Rightarrow p = \frac{x}{n}
\end{equation}
Der Schätzer für $p$ ist somit der relative Anteil der roten Kugeln an der Gesamtanzahl der Kugeln. \\\\
\textbf{Beispiel 2}: Beispiel 1 wird erweitert. Es wird nun eine zweite Stichprobe gezogen. 
Stichprobe 1: $n_1 = 10$, $x_1 = 4$, Stichprobe 2: $n_2 = 20$, $x_2 = 6$.
Daten sind unabhängig voneinander. Die Daten (Posterioriverteilung) der 1. Stichprobe dienen nun
als Prioridichte für die 2. Stichprobe. Man erhält somit:
\begin{equation}
P(p|n_1,x_1,n_2,x_2) = \frac{P(p|n_1,x_1) \cdot P(p|n_2,x_2)}{P(n_1,x_1,n_2,x_2)}
\end{equation}
Dabei ist die Prioridichte identisch zur Posterioridichte der 1. Stichprobe, siehe Gleichung \eqref{eq:posterior}.
Die Posterioridichte der 2. Stichprobe ergibt sich somit zu:
\begin{equation}
P(p|n_1,x_1,n_2,x_2) = \frac{\binom{n_1+n_2}{x_1+x_2} \cdot p^{x_1} \cdot (1-p)^{n_1-x_1} \cdot p^{x_2} \cdot (1-p)^{n_2-x_2}}{P(n_1,x_1,n_2,x_2)}
\end{equation}
Oder mithilfe der Beta-Verteilung:
\begin{equation}
  P(p|n_1,x_1,n_2,x_2) = \frac{\Gamma(n_1+n_2+1)}{\Gamma(x_1+x_2+1)\cdot\Gamma(n_1+n_2-x_1-x_2+1)} \cdot p^{x_1+x_2} \cdot (1-p)^{n_1+n_2-x_1-x_2}
\end{equation}
Die Daten der 1. und 2. Stichprobe könnnen somit kombiniert werden.
Für die Daten $n_1 = 10$, $x_1 = 4$, $n_2 = 20$, $x_2 = 6$:
\begin{equation}
P(p|10,4,20,6) = 931 395 465p^{10} \cdot (1-p)^{20}
\end{equation}

\subsubsection{Punktschätzer in der bayesianischen Statistik}
Im folgenden wird die Schätzung eines Parameters mithilfe der Bayes-Strategie erläutert. \\
Die möglichen Schätzwerte der Parameter $x$ werden als $\hat{x}$ bezeichnet. Die wahren Parameter werden als $x$ bezeichnet. \\
Es wird eine Kostenfunktion $L(\hat{x},x)$ definiert, die die Kosten für die Schätzung $\hat{x}$ des wahren Parameters $x$ angibt.
Dies bedeutet, dass die Kostenfunktion die Differenz zwischen dem wahren Parameter $x$ und der Schätzung $\hat{x}$ angibt.
Dabei gibt es verschiedene Kostenfunktionen, die verwendet werden können. \parencite[65]{EinfBayesStatistik} \\\\
Die \textbf{quadratische Kostenfunktion} ist definiert als: $L(x-\hat{x}) = (x-\hat{x})\Sigma^{-1}(x-\hat{x})$. \\
Diese gibt den quadratischen Abstand zwischen dem wahren Parameter $x$ und der Schätzung $\hat{x}$ an.
Die zu erwartenden Kosten werden berechnet mit dem Erwartungswert der Kostenfunktion.
Diese Schätzung führt zu dem Erwartungswert von $x$, das heißt $\hat{x} = E(x)$. \parencite[65-66]{EinfBayesStatistik} \\\\
Die \textbf{Kostenfunktion der absoluten Fehler} ist definiert als: $L(x,\hat{x}) = |x-\hat{x}|$.
Diese gibt den absoluten Abstand zwischen $x$ und $\hat{x}$ an.
Die Schätzung mit dem absoluten Fehler ergibt den Median der Verteilung, das heißt $F(\hat{x}_med) = 0.5$ \parencite[67-68]{EinfBayesStatistik} \\\\
Die \textbf{Null-Eins-Kostenfunktion} bedeutet, dass es entweder Kosten oder keine Kosten gibt.
Diese ist definiert durch: $L(x-\hat{x}) = 
\begin{cases}
  0 & \text{für } |x-\hat{x}| < b \\
  a & \text{für } |x-\hat{x}| \geq b
\end{cases}$,\\
wobei $a$ und $b$ als Konstaten angenommen werden. Wenn der Fall $b \to 0$ betrachtet wird,
ergibt sich als Schätzer das Argument des Maximums der Posterioriverteilung, das heißt $\hat{x}_M = \arg \max \; p(x|y)$. \parencite[68-69]{EinfBayesStatistik}


\newpage

\subsection{Binomiale Verteilung und deren bayesianische Interpretation}
\newpage

\subsection{Markov Chain Monte Carlo (MCMC) Methoden}
\subsubsection{Einführung in MCMC-Methoden}
Bei einer direkten Simulation wird vorrausgesetzt, dass die Verteilung der Zufallsvariablen bekannt ist.
Dies ist jedoch in der Praxis nicht immer gegeben.
Die Berechnung der Posterioriverteilung ist analytisch oft nicht möglich, vor allem bei komplexen Modellen oder hohen Dimensionen. \\\\
Die Markov Chain Monte Carlo (MCMC) Methoden sind eine Klasse von Algorithmen, die es ermöglichen, eine Stichprobe aus einer Verteilung zu ziehen, ohne die Verteilung zu kennen. \parencite[179]{MonteCarloAlgorithmen} \\
Diese Methoden verwenden zwei Konzepte: Markov-Ketten und Monte Carlo-Methoden. \\
Eine Markov-Kette ist eine Folge von Zufallsvariablen, die die Markov-Eigenschaft erfüllen. 
Die Markov-Eigenschaft sagt aus, dass die nächste Zufallsvariable nicht von den vorherigen Zufallsvariablen, sondern nur von der letzten Zufallsvariable abhängt. 
Das bedeutet, dass die Wahrscheinlichkeit, im nächsten Zustand $X_n+1$ zu landen, nur von $X_n$ abhängt. 
Die Übergangswahrscheinlichkeit zwischen den Zuständen kann in einer Übergangsmatrix dargestellt werden. \parencite[188f.]{MonteCarloAlgorithmen} \\
Die Monte Carlo-Methoden sind eine Gruppe von Algorithmen, die es ermöglichen, Zufallsvariablen zu schätzen, indem Zufallszahlen generiert werden. 
Sie erzeugen zufällige Stichproben, um eine Näherung der Verteilung zu erhalten. \parencite[14f.]{MonteCarloAlgorithmen} \\\\
Die MCMC-Methoden nutzen die Monte Carlo-Methoden, um eine Markov-Kette zu simulieren. Diese Technik ist besonders nützlich, um eine Posterioriverteilung zu schätzen, wenn direkte Berechnungen nicht möglich sind. \parencite[179]{MonteCarloAlgorithmen} \\
Im folgenden wird der Metropolis-Hastings-Algorithmus erläutert, der eine der bekanntesten MCMC-Methoden ist.
\newpage

\subsection{Konvergenzkriterien und Diagnosewerkzeuge für MCMC-Simulationen}
\newpage

\section{Praktischer Teil}

\subsection{Implementierung bayesianischer Modelle unter Verwendung in Python}
\newpage

\subsection{Anwendung der Modelle auf verschiedene Datensätze}
\newpage

\subsection{Durchführung von MCMC-Simulationen}
\newpage

\subsection{Interpretation der Ergebnisse}
\newpage

\subsection{Vergleich mit klassischen Methoden}
\newpage

\section{Zusammenfassung und Ausblick}
\newpage


\section{Literaturverzeichnis} 

\printbibliography 
\newpage

\section{Selbstständigkeitserklärung}

\end{document}